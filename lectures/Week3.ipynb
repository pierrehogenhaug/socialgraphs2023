{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This week we'll get started on modern network science. We'll focus on two key results that kick-started a revolution in our understanding of networks.\n",
    "\n",
    "* Problems with random networks as models for real networks and the Watts-Strogatz model\n",
    "* Scale-free networks and the Barabasi-Albert model\n",
    "\n",
    "In addition to this, we will also talk about the \n",
    "* Configuration model for creating random networks.\n",
    "\n",
    "But before we can get started, there's the bookkeeping stuff, the admin things. Do watch it - the material below tells you about key elements of how to do well in class, assignments and stuff.\n",
    "\n",
    "And the good news is that after today, we can take it easy with admin stuff for a while. We'll restart this aspect when we get closer to the project assignments that we finish the class with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0.0: Two surveys to help improve this course\n",
    "\n",
    "I want to give you the best-possible course. To do this, I collect data from you while this course is running. Today, I will collect 2 surveys.\n",
    "\n",
    "### Survey 1:\n",
    "This survey will help me understand how the first couple of weeks affected your perceptions of Networks and this course. Please go to [DTU learn](https://learn.inside.dtu.dk/) -> Activities -> Surveys and complete the survey \"My thoughts on Social Graphs and Interactions II\" and help me improve this course.\n",
    "\n",
    "### Running evaluation 1\n",
    "I want to hear your thoughts on the way we are running this course so that I can improve the course while you are still taking it. Please think of what you like and dislike about the course and share your constructive suggestions with me on [DTU learn](https://learn.inside.dtu.dk/) -> Activities -> Surveys -> \"Running evaluation of course I\"\n",
    "\n",
    "> You can hear me describe the thoughts behind this evaluation in this [video lecture](https://www.dropbox.com/scl/fi/ytursoj8rls423bcnpz6q/RunningEvaluationI.mp4?rlkey=58093lleggkpha85dtubxq1kf&dl=0). Link: https://www.dropbox.com/scl/fi/ytursoj8rls423bcnpz6q/RunningEvaluationI.mp4?rlkey=58093lleggkpha85dtubxq1kf&dl=0\n",
    "\n",
    "**_Thanks so much for helping us improve the course!_**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 0.1: The admin stuff \n",
    "### (Why we use Peer Evaluations Edition)\n",
    "\n",
    "We use the system [Peergrade.io](http://peergrade.io/) to get you better feedback and make you smarter. In the video below, I explain why that is the case. There are a lot of good reasons that peer evaluations are great, so watch [the video](https://www.dropbox.com/scl/fi/r4liy92ell1dkjq1ye9v4/AdminWeek3.mp4?rlkey=0coke8ubcmapkxbznrx3ndqc7&dl=0) :)\n",
    "\n",
    "Link: https://www.dropbox.com/scl/fi/r4liy92ell1dkjq1ye9v4/AdminWeek3.mp4?rlkey=0coke8ubcmapkxbznrx3ndqc7&dl=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Part 1: Small world networks\n",
    "\n",
    "Once again, we'll start with some lecturing. So it's time to [watch a little video](https://www.dropbox.com/scl/fi/8b65w8vkitxlgc3huzy6p/SmallWorlds.mp4?rlkey=are1v0hu7l42gau9qxbisuj1q&dl=0) to get you started.\n",
    "\n",
    "> **_Video Lecture_**: Some properties of real world networks. Clustering and small paths. The Watts-Strogatz model.  Link: https://www.dropbox.com/scl/fi/8b65w8vkitxlgc3huzy6p/SmallWorlds.mp4?rlkey=are1v0hu7l42gau9qxbisuj1q&dl=0\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next up is fun with reading the textbook. There's lots of goodies left in Chapter 3 that covers the stuff I've just covered in the video from a slightly different angle. \n",
    "> \n",
    "> *Reading*: For this part, we'll read the remaining part of *Network Science* Chapter 3, Section 3.5 - 3.10, with ***emphasis*** on 3.8 and 3.9\\.\n",
    "> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Exercises*: Did you really read the text? Answer the following questions (no calculations needed) in your IPython notebook. \n",
    "> \n",
    "> * What's the problem with random networks as a model for real-world networks according to the argument in section 3.5 (near the end)?\n",
    "> * List the four regimes that characterize random networks as a function of $\\langle k \\rangle$.\n",
    "> * According to the book, why is it a problem for random networks (in terms of being a model for real-world networks) that the degree-dependent clustering $C(k)$ decreases as a function of $k$ in real-world networks?\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of exercises departs from the book by presenting a little study of the Watts-Strogatz (WS) model. We're going to see just how few random links the WS model needs to dramatically shorten the path-lengths in the network. And while doing that, we'll practice using `networkx`, writing loops, and plotting nice figures.\n",
    "\n",
    "> *Exercises*: WS edition.\n",
    "> \n",
    "> * First, let's use `networkx` to play around with WS graphs. Use `nx.watts_strogatz_graph` to generate 3 graphs with 500 nodes each, average degree = 4, and rewiring probablity $p = 0, 0.1,$ and  $1$. Calculate the average shortest path length $\\langle d \\rangle$ for each one. Describe what happens to the network when $p = 1$.\n",
    "> * Generate a lot of networks with different values of $p$. You will notice that paths are short when $p$ is close to one and they are long when $p = 0$. What's the value of $p$ for which the average shortest path length gets close to the short paths we find in a fully randomized network.\n",
    "> * Let's investigate this behavior in detail. Generate 50 networks with $N = 500$, $\\langle k \\rangle = 4$, for each of $p = \\{0, 0.01, 0.03, 0.05, 0.1, 0.2\\}$. Calculate the average of $\\langle d \\rangle$ as well as the standard deviation over the 50 networks, to create a plot that shows how the path length decreases very quickly with only a little fraction of re-wiring. Use the standard deviation to add [errorbars](https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.errorbar.html) to the plot. My version of the plot is below (since a picture's worth 1000 words).\n",
    "> \n",
    "\n",
    "![Sune's version](https://raw.githubusercontent.com/SocialComplexityLab/socialgraphs2021/main/files/ws.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Scale-free networks\n",
    "\n",
    "The text book uses two whole chapters on the scale free property. We'll try to cover it a bit faster. As always, [let's start by getting my take on the whole thing](https://www.dropbox.com/scl/fi/tn4dxkwe3w58qtdaxx077/BarabasiAlbert.mp4?rlkey=xw7fkwti5xdt81ej7p2ky22vr&dl=0).\n",
    "\n",
    "> **_Video Lecture_**: The scale free property and the Barabasi-Albert Model. Link: https://www.dropbox.com/scl/fi/tn4dxkwe3w58qtdaxx077/BarabasiAlbert.mp4?rlkey=xw7fkwti5xdt81ej7p2ky22vr&dl=0\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now it's time for you guys to read. Recall that Barabasi (who wrote the textbook) discovered power-laws.\n",
    "\n",
    "> *Reading*: Now we dig into the extended history and and theory behind Scale-Free networks and the Barabasi-Albert Model.\n",
    "> \n",
    "> * Chapter 4, Section 4.1 - 4.7\\.\n",
    "> * Chapter 5, section 5.1 - 5.5\\.\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> *Exercises*: BA edition.\n",
    "> \n",
    "> First a couple of questions to make sure that you've actually read the text.\n",
    "> \n",
    "> * What are the three slope dependent regimes of complex networks with power-law degree distributions? Briefly describe each one. (You will have to skim chp 4.7 to answer this one).\n",
    "> * What are the three regimes we find in non-linear preferential attachement? (chapter 5) Briefly describe each one.\n",
    "> \n",
    "> We're going to create our own Barabasi-Albert model (a special case) in right in a `notebook`. Follow the recipe below for success:\n",
    "> \n",
    "> * First create a graph consisting of a single link. (You can call the nodes anything, but I would simply use integers as names).\n",
    "> * Now add another node, connecting one of the existing nodes in proportion to their degree.\n",
    "> * Keep going until you have a 100 node network.\n",
    ">   * *Hint*: The difficult part here is connecting to each node according to their degree. The way I do it is: generate a list of all edges (e.g. pairs of nodes), then flatten it (e.g. remove connection information). That list contains each node in proportion to its connections, thus drawing a random node from that list (e.g. using `random.choice`) corresponds to selecting a node with probability proportional to it's degree.\n",
    "> * Plot the network. \n",
    "> * Add more nodes until you have a 5000 node network.\n",
    "> * What's the maximum and minimum degree?\n",
    "> * Now, bin the degree distribution using `numpy.histogram`.\n",
    "> * Plot the distribution. Plot it with both linear and log-log axes.\n",
    "> \n",
    "> ![Sune's version](https://raw.githubusercontent.com/SocialComplexityLab/socialgraphs2021/main/files/ba.png)\n",
    "> \n",
    "> Next step is to explore the [Friendship paradox](https://en.wikipedia.org/wiki/Friendship_paradox). This paradox states that _almost everyone_ has fewer friends than their friends have, on average\\*. This sounds crazy, but is actually an almost trivial consequence of living in a social network with a power-law degree distribution. The explanation is that almost everyone is friends with a hub, that drives up the average degree of the friends. Let's explore that in the 5000 node BA network we've just generated. Do the following:\n",
    "> \n",
    "> * Pick a node $i$ at random (e.g. use `random.choice`). [Find its degree](https://networkx.github.io/documentation/stable/reference/classes/generated/networkx.Graph.degree.html).\n",
    "> * Find $i$'s [neighbors](https://networkx.github.io/documentation/networkx-1.10/reference/generated/networkx.Graph.neighbors.html?highlight=neighbors#networkx.Graph.neighbors). And calculate their average degree.\n",
    "> * Compare the two numbers to check if it's true that $i$'s friends (on average) have more friends than $i$.\n",
    "> * Do this 1000 times. How many out of those 1000 times is the friendship paradox true?\n",
    "> \n",
    "> Finally, we'll build a network of same size and degree, using the growth mechanism without the preferential attachment. \n",
    "> \n",
    "> * Compare to the ER network of same size and same $p$. What are the differences? Explain in your own words. *Hint*: To get started, take a look at the degree distribution, and study the number of connected components.\n",
    ">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 3: Configuration-model networks\n",
    "\n",
    "\n",
    "The Barabasi-Albert model introduced us to the importance of degree distributions. A very important class of random graphs allows us to create networks with _any_ degree distribution of our choice. The model used for creating such networks is called the **configuration model**\n",
    "\n",
    "> **_Video Lecture_**: [The configuration model.](https://www.dropbox.com/scl/fi/9ti390zxbf3ymnuogp6a4/ConfigurationModel.mp4?rlkey=o9jclx4j77umv0d43htcozrp4&dl=0) Link: https://www.dropbox.com/scl/fi/9ti390zxbf3ymnuogp6a4/ConfigurationModel.mp4?rlkey=o9jclx4j77umv0d43htcozrp4&dl=0\n",
    "> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, we will write a function that lets us create configuration model networks.\n",
    "\n",
    "> *Exercises*: Configuration-model edition.\n",
    "> \n",
    "> * First, let's create a configuration-model network with 4 nodes and the degree sequence [2,2,3,3]. That is, node 0 should have degree 2, node 1 degree 2, node 2 degree 3 and node 3 degree 3. In the code block following these exercises, I have created the skeleton for a function `configuration_model` that takes a degree sequence `degrees` like this as its input. \n",
    "> * Between the comments \"STEP ONE GOES HERE\" and \"STEP ONE ENDS HERE\" in the following code block, write some code that appends the integer _i_ to the list `halfedges` _k_ times, if the array `degrees` has _k_ on its _i_ th entry. _Hint:_ I solved this with a nested `for` loop.\n",
    "> * Between the comments \"STEP TWO GOES HERE\" and \"STEP TWO ENDS HERE\" write some code that shuffles the `halfedges` list. _Hint:_ you could use the numpy function `np.random.shuffle()` for this.\n",
    "> * `halfedges` now contains a lot of integers. Each integer _i_ represents an halfedge that node _i_ should have in your final network. Now we are ready to form edges from these halfedges. Between the comments \"STEP THREE GOES HERE\" and \"STEP THREE ENDS HERE\", write some code that appends a tuple _(i,j)_ to the list `edgelist` for every pair _(i,j)_ where _i_ is the integer on an even-numbered entry in `halfedges` and _j_ is the integer on the odd-numbered entry following that even-numbered entry.\n",
    "> * Create a networkx graph with the degree sequence [2,2,3,3] using your `configuration_model` function. Does it look like what you expect? Do you notice any peculiar things about the network you created?\n",
    "> * Now create another networkx graph with 200 nodes of degree 6 using your `configuration_model` function. Confirm that all nodes have degree 6.\n",
    "> * Repeat the latter two questions using the `networkx` command `nx.configuration_model()` to create the networks from degree sequences.\n",
    "> * Now extract the degree sequence for one of the Barabasi-Albert model you created in the previous exercise. Create a configuration-model network with that same degree sequence. \n",
    "> * _Bonus question_: Although these two latter networks may seem very similar, there are subtle differences. Can you find any?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configuration_model (degrees) :\n",
    "    \n",
    "    halfedges = [] # a list of halfedges\n",
    "    \n",
    "    # Now append integer i to `halfedges` k times if the ith entry of degrees is equal to k:\n",
    "    # STEP ONE GOES HERE..\n",
    "    # .\n",
    "    # .\n",
    "    # .\n",
    "    # STEP ONE ENDS HERE\n",
    "    print(\"Check if the following ouput matches what you expect 'halfedges' to look like\")\n",
    "    print(halfedges)\n",
    "    \n",
    "    # Shuffle the list halfedges\n",
    "    # STEP TWO GOES HERE..\n",
    "    # .\n",
    "    # .\n",
    "    # .\n",
    "    # STEP TWO ENDS HERE    \n",
    "    \n",
    "    # Append the resulting edges to the list `edgelist` as tuples \n",
    "    # [that is, append (i,j) if i and j should be connected by and edge]\n",
    "    \n",
    "    edgelist = [] # This will contain tuples (i,j) indicating edges between nodes i and j.    \n",
    "    # STEP THREE GOES HERE..\n",
    "    # .\n",
    "    # .\n",
    "    # .\n",
    "    # STEP THREE ENDS HERE    \n",
    "\n",
    "    return edgelist #Return list of tuples indicating edges\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
